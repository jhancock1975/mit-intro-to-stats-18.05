\documentclass[a4paper,11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage[backend=bibtex]{biblatex}
\bibliography{biblio}

% for probability trees
\usepackage{tikz}
\usetikzlibrary{trees}

%for strikethrough text
\usepackage{soul}

%for R source code listing
\usepackage{listings}

% For not indenting the first line of paragraphs:
\setlength{\parindent}{0pt}

% define the title
\author{John Hancock}
\title{Answers To Questions in Conditional Probability, Independence, 
Bayes Theorem 18.05}

\begin{document}
% generates the title
\maketitle
% insert the table of contents
\tableofcontents
\section{References and License}
The material for the course is licensed under the terms at 
\url{http://ocw.mit.edu/terms}.

In this document, we are answering the questions in \cite{slides3}.

We use documentation in \cite{texInsertText} for properly writing the
\LaTeX source code for this document.
 
\label{prob1}
\section{Probability At Least 3 Heads, Given First Toss Tails}

We are tossing a coin four times. Therefore we define the sample space
\begin{equation}
  \Omega = \left\{ \left( x_{1}, x_{2}, x_{3}, x_{4} \right), 
    x_{1}, x_{2}, x_{3}, x_{4} \in \left\{H, T \right\} \right\}
\end{equation}

$ \left| \Omega \right| = 16$

We assume all outcomes are equally likely.

$A$ is the event that at we toss heads at least 3 times.

$B$ is the event that we toss tails the first time.


We use the definition of conditional probability to cacluate
$P \left( A \mid B \right)$.

\begin{equation} \label{defCondProb}
P \left( A \mid B \right) = \frac{ P \left( A \cap B \right) } 
  { P \left( B \right) } \text{, Provided  } P \left( B \right) \neq 0
\end{equation}

$P \left(A \right) = \frac{5}{16}$ since there are 5 elements of $\Omega$
that represent the event that we toss heads at least three times, and
we assume all outcomes are equally likely.

These are:$\left(T,H,H,H \right)$, $\left(H,T,H,H \right)$, 
$\left(H,H,T,H \right)$, $\left(H,H,H,T \right)$, 
$\left(H,H,H,H \right)$.

The elements of $B$ are $ \left(T, T, T, T \right) $,
$ \left(T, T, T, H \right) $, $ \left(T, T, H, T \right) $,
$ \left(T, T, H, H \right) $, $ \left(T, H, T, T \right) $,
$ \left(T, H, T, H \right) $, $ \left(T, H, H, T \right) $,
$ \left(T, H, H, H \right) $.

By inspection $ A \cap B $ is the element $\left( T, H, H, H \right)$.

We substitute values into \ref{defCondProb} to get
\begin{equation}
  P \left( A \mid B \right) = \frac {\frac{1}{16}} {\frac{8}{16}} = 
    \frac{1}{8}
\end{equation}

\section{Probability First Toss Tails, Given At Least 3 Heads}

We use \ref{defCondProb} and definitions of the sets $\Omega$, $A$, 
$A \cap B$, and $B$ that we define in section \ref{prob1}. In addition
we assume all outcomes are equally likely.

We use \ref{defCondProb} to get
\begin{equation}
P \left( B \mid A \right) = \frac{P \left( B \cap A \right)}
  { P \left( A \right) } \text{, Provided } P\left( A \right) \neq 0
\end{equation}

The $\cap$ operator is commutative, so $P \left( A \cap B \right)
 = P \left( B \cap A \right)$, and we discover 
 $P \left( A \cap B \right)$ in section \ref{prob1}.
 
Therefore,

\begin{equation}
P \left( B \mid A \right) = \frac{ \frac{1}{16} }{ \frac{5}{16} }
  = \frac{1}{5}
\end{equation}

\section{Probability Urn}
\subsection{Probability Second Ball Red}

Orloff and Bloom ask the following question in \cite{slides3}, "What is 
the probability the second ball is red?"

We are given the probability tree below:

% Set the overall layout of the tree
\tikzstyle{level 1}=[level distance=3.5cm, sibling distance=3.5cm]
\tikzstyle{level 2}=[level distance=3.5cm, sibling distance=2cm]
\tikzstyle{level 3}=[level distance=3.5cm, sibling distance=2cm]


% Define styles for bags and leafs
\tikzstyle{bag} = [text width=4em, text centered]
\tikzstyle{end} = [circle, minimum width=3pt,fill, inner sep=0pt]

\begin{tikzpicture}[grow=right, sloped]
\node[end, label=] {}
    child {
        node[bag] {$R_{1}$}        
           child {
                node[end, label=right:
                    {$R_{2} \cap R_{1} $}] {}
                edge from parent
                node[above]  {$ P \left( R_{2} \mid R_{1} \right) = \frac{4}{7}$}
            }
            child {
                node[end, label=right:
                    {$R_{2} \cap G_{2}$}] {}
                edge from parent
                node[above]  {$ P\left( G_{2} \mid R_{1} \right) = \frac{3}{7}$}
            }
            edge from parent 
            node[above]  {$ P \left( R_{1} \right) = \frac{5}{7}$}
    }
    child {
        node[bag] {$G_{1}$}        
        child {
                node[end, label=right:
                    {$R_{2} \cap G_{1}$}] {}
                edge from parent
                node[above]  {$ P \left( R_{2} \mid G_{1} \right)  = \frac{6}{7}$}
            }
            child {
                node[end, label=right:
                    {$G_{2} \cap G_{1}$}] {}
                edge from parent
                node[above]  {$ P \left( G_{2} \mid G_{1} \right) = \frac{1}{7}$}
            }
        edge from parent         
            node[above]  {$ P\left( G_{1} \right) = \frac{2}{7}$}
    };
\end{tikzpicture}


We use the law of total probability to write an equation for 
$P \left( R_{2} \right)$.

\begin{equation} \label{R2Prob}
  P \left( R_{2} \right) = P \left( R_{1} \cap R_{2} \right) +
    P\left( G_{1} \cap R_{2} \right)
\end{equation}

Now we can use the definition of conditional probability to rewrite
\ref{R2Prob}:

\begin{equation} \label{R2ProbApplyDef}
  P \left( R_{2} \right) = P \left( R_{2} \mid R_{1} \right) 
    P \left( R_{1} \right) +
    P\left( R_{2} \mid G_{1} \right) P \left( R_{1} \right)
\end{equation}

Orloff and Bloom give us the probabilities in \ref{R2ProbApplyDef} in 
the probability tree above, so we can use them to compute 
$P\left( R_{2} \right)$.

\begin{equation} \label{R2PlugNumbers}
  P \left( R_{2} \right) = \left( \frac {4}{7} \right) 
    \left( \frac{5}{7} \right) +
    \left( \frac {6}{7} \right) \left( \frac{2}{7} \right)
  = \frac{20}{49} + \frac{12}{49} = \frac{32}{49} \approx 0.653
\end{equation}

\subsection{Probability First Ball Red, Given second Ball Red}

To answer the question, "What is the probability the first ball was red 
given the second ball was red?" \cite{slides3}

This question is asking for $P \left( R_{1} \mid R_{2} \right)$.

Since we know $P\left( R_{2} \mid R_{1} \right)$, we apply Bayes Theorem
to compute $P \left( R_{1} \mid R_{2} \right)$.

\begin{equation} \label{bayesR1GivenR2}
P \left( R_{1} \mid R_{2} \right) = 
  \frac{ P \left( R_{2} \mid R_{1} \right) P \left( R_{1} \right)}
    {P \left( R_{2} \right)}
\end{equation}

Bloom and Orloff give us the values for all of the probabilities in the
right hand side of \ref{bayesR1GivenR2} in the probability tree above.

Therefore 

\begin{equation} \label{bayesR1GivenR2}
P \left( R_{1} \mid R_{2} \right) = 
  \frac{ \left( \frac{4}{7} \right) \left( \frac{5}{7} \right)} 
    {\frac{32}{49}} 
  = \left( \frac{20}{49} \right) 
      \left( \frac{49}{32} \right)
  = \frac{20}{32} \approx 0.625
\end{equation}

\section{Concept Questions on Probability Trees}
In this section, we answer questions about the probability tree that
Orloff and Bloom give in \cite{slides3}.

\begin{tikzpicture}[grow=down, sloped]
\node[end, label=] {}
    child {
        node[bag] {$A_{1}$}
        child {
          node[bag] {$B_{1}$}
          child {
            node[end, label=below: {$C_{1}$}]{}
            edge from parent node[above] {}
          }
          child {
            node[end, label=right: {$C_{2}$}]{}
            edge from parent node[above]  {}
          }     
          edge from parent node[above] {}
        }
        child {
          node[bag] {$B_{2}$}
          child {
            node[end, label = left: {$C_{1}$}]{}
            edge from parent node[above] {z}
          }
          child {
            node[end, label = below: {$C_{2}$}]{}
            edge from parent node[above]  {}
          }
          edge from parent node[above]  {y}
        }
        edge from parent node[above] {x}
    }
    child {
        node[bag] {$A_{2}$}
        child {
          node[bag] {$B_{1}$}
          child {
            node[end, label=below: {$C_{1}$}]{}
            edge from parent node[above] {}
          }
          child {
            node[end, label=right: {$C_{2}$}]{}
            edge from parent node[above]  {}
          }
          edge from parent node[above] {}
        }
        child {
          node[bag] {$B_{2}$}
          child {
            node[end, label = left: {$C_{1}$}]{}
            edge from parent node[above] {}
          }
          child {
            node[end, label = below: {$C_{2}$}]{}
            edge from parent node[above]  {}
          }
          edge from parent node[above]  {}
        }
        edge from parent node[above]  {}
    };
\end{tikzpicture}

The edge labeled, "x," in the figure above represents 
$P \left( A_{1} \right)$.

The edge labeled, "y," in the figure above represets
$P \left( B_{2} \mid A_{1} \right)$.

The edge labeled, "z," in the figure above represents 
$P \left( C_{1} \mid A_{1} \cap B_{2} \right)$.  We read section 5.1,
titled, "Shorthand vs. precise trees," in \cite{slides3} in order to 
understand what the edge labeled, "z," represents.  This section 
explains that nodes having a distance of two or more edges to the
root of the tree represent the probabilities of intersections of sets
of outcomes.

The node labeled, "$C_{1}$," at the end of the path, $A_{1}$, 
$B_{2}$, $C_{2}$, represents the event, $A_{1} \cap B_{2} \cap C_{1}$.
This is also clear when we read section 5.1,
titled, "Shorthand vs. precise trees," in \cite{slides3}.

\section{Monty Hall Problem}

One should switch after Monty shows a goat.

We find a clear explanation of why in \cite{paradeMag}.

We reproduce the table in \cite{paradeMag} that explains why one should
always switch:

\begin{center}
  \begin{tabular}{ | c | c | c | c | c |}
    \hline
     & Door 1 & Door 2 & Door 3 & result \\ \hline
    Game 1 & Auto & Goat & Goat & Switch and you lose. \\ \hline
    Game 2 & Goat & Auto & Goat & Switch and you win. \\ \hline
    Game 3 & Goat & Goat & Auto & Switch and you win. \\ \hline
    Game 4 & Auto & Goat & Goat & Stay and you win. \\ \hline
    Game 5 & Goat & Auto & Goat & Stay and you lose. \\ \hline
    Game 6 & Goat & Goat & Auto & Stay and you lose.\\ \hline
  \end{tabular}
\end{center}

This table illustrates the case where we always choose door number one,
and the cars and goats are placed in any of the three possible ways
to put the cars and goats behind doors one, two or three. 

We can assume we always choose door number one without loss of 
generality because always choosing a different door results
in a permutation in the values of the last column of the table above.

The first three rows of the table show the result of switching our 
choice of door after Monty shows one door, other than the one we choose,
that has a goat behind it.

The last three rows of the table show the result of not switching our 
choice of door after Monty shows one door, other than the one we choose,
that has a goat behind it.

We inspect this table to find that for any possible location of the
car, two out of the three possible outcomes result in a win if we
switch.  On the other hand, for any possible location of the car,
one out of three possible outcomes result in a win if we do not switch.

Therefore we should always switch.

\section{Independent Events}

We roll two dice.

We define the following events:

\begin{itemize}
  \item $A$ is the event that we roll a 3 with the first die.
  \item $B$ is the event the sum of the values we roll for both dice is 6.
\end{itemize}

We assume that when we roll the two dice, for any die, rolling any
value one through six is equally likely.

We show that $A$ and $B$ are not independent events.

$A$ and $B$ are independent events if, and only if, 

\begin{equation}
  P \left( A \cap B \right) = P \left( A \right) \cdot P \left( B \right)
\end{equation}

There are 6 outcomes in $A$ because the first die we roll must land on
three, but the second die we roll can land on any of the six possible
values. We count 6 sequences of integers where the first element of
the sequence is a 3, and the second element has any value from one
to six.

There are $36$ possible sequences of outcomes when we roll two dice.

Therefore $P \left( A \right) = \frac{6}{36}$.

There are $5$ outcomes in $B$.  This is because there are $5$ sequences
of two integers with values from one to six that add to 6.  They are:
$\left(1, 5 \right), \left(2, 4 \right), \left(3, 3 \right), 
\left(4, 2 \right),$ and $\left(5, 1 \right)$.

There are $36$ possible sequences of outcomes when we roll two dice.

Therefore $P \left( B \right) = {5}{36}$.

The only outcome in $A$ that is also in $B$ is where we roll a three
with the first die, and a three with the second die.

There are $36$ possible sequences of outcomes when we roll two dice.

Therefore $P\left( A \cap B \right) = \frac{1}{36} = \frac{6}{216}$.

\begin{equation}
  \left( \frac{6}{36} \right) \left( \frac{5}{36} \right) =
    \frac {30}{216} \neq \frac{6}{216}
\end{equation}

So $A$ and $B$ are not independent events.
\printbibliography{}
\end{document}
